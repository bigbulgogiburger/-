{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 금융정보방 게시판에 있는 글들 다 모아오기.\n",
    "#### author : 편도훈\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import datetime\n",
    "import os\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개 회사의 정보와 폴더이름을 가지고 게시판에 들어가서 크롤링하는 function입니다.\n",
    "\n",
    "def crawl_(company_info_lists,folder_name):\n",
    "\n",
    "    # 크롬드라이버가 연결되어 있는 주소 저장\n",
    "    chromedriver ='E:/big12/python-project/note/driver/chromedriver.exe'\n",
    "\n",
    "    # 크롬드라이버 연결\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    print(company_info_lists)\n",
    "    #업종 사이트 연결\n",
    "    title=[]\n",
    "    times=[]\n",
    "    contents=[]\n",
    "    address=[]\n",
    "    #받아온 정보의 index 0 인 코드를 넣습니다. page는 아무렇게나 하셔도 상관 없습니다. but 저는 1번째 페이지만 해놨습니다.\n",
    "    driver.get('https://finance.naver.com/item/board.nhn?code={code}&page={page}'.format(code=company_info_lists[0],page=1))\n",
    "\n",
    "    table = driver.find_element_by_class_name('type2')\n",
    "\n",
    "    #게시글 제목 찾기\n",
    "    title.extend([x.text.replace(\",\",\" \") for x in table.find_elements_by_tag_name('a')]) \n",
    "\n",
    "    #게시글 링크 찾기\n",
    "    address.extend([x.get_attribute('href') for x in table.find_elements_by_tag_name('a')])\n",
    "\n",
    "    #게시글 작성 시간 찾기\n",
    "    times.extend([x.text for x in table.find_elements_by_class_name('tah.p10.gray03') if len(x.text)>10])\n",
    "\n",
    "    #게시글 내용 찾기\n",
    "\n",
    "    for addr in address:\n",
    "        driver.get(addr)\n",
    "        contents.append(driver.find_element_by_id('body').text.replace(\",\",\" \"))\n",
    "\n",
    "    now= datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    board_contents = pd.DataFrame(\n",
    "        {'title':title,'contents':contents,'time':times}\n",
    "    )\n",
    "    board_contents.to_csv('./categories/'+folder_name+'/'+company_info_lists[1]+now+'.csv', encoding='utf-8')\n",
    "    driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #파일경로\n",
    "# file_paths= glob('E:/big12/python-project/note/categories/*.csv')\n",
    "# file_path_root ='E:/big12/python-project/note/categories/'\n",
    "\n",
    "def folder_file_separator(file_paths):\n",
    "    file_path_root ='E:/big12/python-project/note/categories/'\n",
    "#파일이름을 기초로 찾아보기.\n",
    "    for file_path in file_paths:\n",
    "        #종목 폴더이름\n",
    "        folder_name=[]\n",
    "        folder_name = str(file_path.split('\\\\')[1].split('.')[0])\n",
    "        try:\n",
    "            if not(os.path.isdir(file_path_root+folder_name)):\n",
    "                os.makedirs(os.path.join(file_path_root+folder_name))\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.EEXIST:\n",
    "                print(\"Failed to create directory!!!!!\")\n",
    "                raise\n",
    "        time.sleep(0.7)\n",
    "\n",
    "        #종목 회사 별코드\n",
    "        code_list= [x[1:] for x in np.array(pd.read_csv(file_path)['code'])]\n",
    "        #종목별회사명\n",
    "        name_list = [x for x in np.array(pd.read_csv(file_path)['name'])]\n",
    "        company_info_list=[]\n",
    "        for code,name in zip(code_list,name_list):\n",
    "            company_info_list.append([code,name])\n",
    "\n",
    "        for company_infos in company_info_list:\n",
    "            print(company_infos,folder_name,'from separator')\n",
    "            crawl_(company_infos,folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['050960', '수산아이앤티'] IT서비스 from separator\n",
      "['011090', '에넥스'] 가구 from separator\n",
      "['003480', '한진중공업홀딩스'] 가스유틸리티 from separator['024940', 'PN풍년'] 가정용기기와용품 from separator\n",
      "\n",
      "['003480', '한진중공업홀딩스']\n",
      "['024940', 'PN풍년']\n",
      "['011090', '에넥스']\n",
      "['050960', '수산아이앤티']\n",
      "['016710', '대성홀딩스'] 가스유틸리티 from separator\n",
      "['134790', '시디즈'] 가구 from separator\n",
      "['039290', '인포뱅크'] IT서비스 from separator\n",
      "['016710', '대성홀딩스']\n",
      "['134790', '시디즈']\n",
      "['039290', '인포뱅크']\n",
      "['192400', '쿠쿠홀딩스']['009240', '한샘'] 가구 from separator\n",
      " 가정용기기와용품 from separator\n",
      "['192400', '쿠쿠홀딩스']\n",
      "['009240', '한샘']\n",
      "['017390', '서울가스'] 가스유틸리티 from separator\n",
      "['307950', '현대오토에버'] IT서비스 from separator\n",
      "['017390', '서울가스']\n",
      "['307950', '현대오토에버']\n",
      "['256150', '한독크린텍'] 가정용기기와용품 from separator\n",
      "['013890', '지누스'] 가구 from separator\n",
      "['013890', '지누스']\n",
      "['256150', '한독크린텍']\n",
      "['348030', '모비릭스'] IT서비스 from separator\n",
      "['348030', '모비릭스']\n",
      "['117580', '대성에너지'] 가스유틸리티 from separator\n",
      "['117580', '대성에너지']\n",
      "['071950', '코아스'] 가구 from separator\n",
      "['071950', '코아스']\n",
      "['060250', 'NHN한국사이버결제'] IT서비스 from separator\n",
      "['060250', 'NHN한국사이버결제']\n",
      "['267290', '경동도시가스'] 가스유틸리티 from separator\n",
      "['037070', '파세코'] 가정용기기와용품 from separator\n",
      "['267290', '경동도시가스']\n",
      "['037070', '파세코']\n",
      "['016800', '퍼시스'] 가구 from separator\n",
      "['016800', '퍼시스']\n",
      "['017940', 'E1'] 가스유틸리티 from separator\n",
      "['017940', 'E1']\n",
      "['056080', '유진로봇'] 가정용기기와용품 from separator\n",
      "['020180', '대신정보통신'] IT서비스 from separator\n",
      "['056080', '유진로봇']\n",
      "['020180', '대신정보통신']\n",
      "['003800', '에이스침대'] 가구 from separator\n",
      "['003800', '에이스침대']\n",
      "['034590', '인천도시가스'] 가스유틸리티 from separator\n",
      "['034590', '인천도시가스']\n",
      "['317870', '엔바이오니아'] 가정용기기와용품 from separator\n",
      "['064480', '브리지텍'] IT서비스 from separator\n",
      "['317870', '엔바이오니아']\n",
      "['064480', '브리지텍']\n",
      "['073190', '듀오백'] 가구 from separator\n",
      "['073190', '듀오백']\n",
      "['014100', '메디앙스'] 가정용품 from separator\n",
      "['014100', '메디앙스']\n",
      "['214180', '민앤지'] IT서비스 from separator\n",
      "['214180', '민앤지']\n",
      "['079430', '현대리바트'] 가구 from separator\n",
      "['079430', '현대리바트']\n",
      "['053620', '태양'] 가정용품 from separator\n",
      "['053620', '태양']\n"
     ]
    }
   ],
   "source": [
    "#파일경로\n",
    "###4개의 멀티쓰레딩으로 정보를 모을겁니다. \n",
    "### 코어의 개수 * 2 하신게 최대 쓰레드라고 보시면 되고요.. 저는 그냥 반정도 욕심내지 않고 하려합니다.\n",
    "### 멀티쓰레딩에 사용되는 모듈 및 function은 from multiprocessing.pool import ThreadPool입니다.\n",
    "### author : 편도훈 a.k.a '중원구 민트초코 패밀리사이즈' 입니다.\n",
    "file_paths_all= glob('E:/big12/python-project/note/categories/*.csv')\n",
    "\n",
    "file_paths1=[]\n",
    "file_paths2=[]\n",
    "file_paths3=[]\n",
    "file_paths4=[]\n",
    "for i in range(len(file_paths_all)):\n",
    "    if i%4==0: file_paths1.append(file_paths_all[i])\n",
    "    elif i%4==1 : file_paths2.append(file_paths_all[i])\n",
    "    elif i%4==2 : file_paths3.append(file_paths_all[i])\n",
    "    elif i%4==3 : file_paths4.append(file_paths_all[i])\n",
    "### starmap은 왠지 모르겠는데 2중리스트를 1중리스트로 풀어서 그 1중리스트를 또 풀어 인자로 전달한다.. .인자만 16개가 되는 대 참 사가\n",
    "### 일어나기 때문에 한번 더 감싸줘서 3중리스트로 안전하고 꼼꼼하게 우겨넣었더니 되더라\n",
    "file_paths_separated_list= [[file_paths1],[file_paths2],[file_paths3],[file_paths4],[file_paths5]]\n",
    "with ThreadPool(4) as tp:\n",
    "    tp.starmap(\n",
    "    folder_file_separator,file_paths_separated_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #파일경로\n",
    "# file_paths= glob('E:/big12/python-project/note/categories/*.csv')\n",
    "# file_path_root ='E:/big12/python-project/note/categories/'\n",
    "# #파일이름을 기초로 찾아보기.\n",
    "# for file_path in file_paths[1:]:\n",
    "#     #종목 폴더이름\n",
    "#     folder_name = str(file_path.split('\\\\')[1].split('.')[0])\n",
    "    \n",
    "#     try:\n",
    "#         if not(os.path.isdir(file_path_root+folder_name)):\n",
    "#             os.makedirs(os.path.join(file_path_root+folder_name))\n",
    "#     except OSError as e:\n",
    "#         if e.errno != errno.EEXIST:\n",
    "#             print(\"Failed to create directory!!!!!\")\n",
    "#             raise\n",
    "#     time.sleep(0.7)\n",
    "    \n",
    "#     #종목 회사 별코드\n",
    "#     code_list= [x[1:] for x in np.array(pd.read_csv(file_path)['code'])]\n",
    "#     #종목별회사명\n",
    "#     name_list = [x for x in np.array(pd.read_csv(file_path)['name'])]\n",
    "#     company_info_list=[]\n",
    "#     for code,name in zip(code_list,name_list):\n",
    "#         company_info_list.append([code,name])\n",
    "        \n",
    "#     for company_infos in company_info_list:\n",
    "#         print(company_infos,folder_name)\n",
    "#         crawl_(company_infos,folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-ml",
   "language": "python",
   "name": "dev-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
